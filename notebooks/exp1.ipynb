{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fde3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce641e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film version of Sandra Bernhard's one-woman of...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I switched this on (from cable) on a whim and ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The `plot' of this film contains a few holes y...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Some amusing humor, some that falls flat, some...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What can you say about this movie? It was not ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Not exactly a new story line, but this romanti...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I first saw this movie as a younger child. My ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Some people have stated that as of the 11th se...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Nothing but the director's juvenile fantasy co...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>****SPOILER ALERT**** All throughout Australia...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "0    Film version of Sandra Bernhard's one-woman of...  negative\n",
       "1    I switched this on (from cable) on a whim and ...  positive\n",
       "2    The `plot' of this film contains a few holes y...  negative\n",
       "3    Some amusing humor, some that falls flat, some...  negative\n",
       "4    What can you say about this movie? It was not ...  negative\n",
       "..                                                 ...       ...\n",
       "995  Not exactly a new story line, but this romanti...  negative\n",
       "996  I first saw this movie as a younger child. My ...  positive\n",
       "997  Some people have stated that as of the 11th se...  positive\n",
       "998  Nothing but the director's juvenile fantasy co...  negative\n",
       "999  ****SPOILER ALERT**** All throughout Australia...  positive\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('IMDB.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf723ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    lemm=WordNetLemmatizer()\n",
    "    text=text.split()\n",
    "    text=[lemm.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_sw(text):\n",
    "    sw=set(stopwords.words('english'))\n",
    "    text=[word for word in str(text).split() if word not in sw]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_num(text):\n",
    "    text=''.join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    text=text.split()\n",
    "    text=[word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punc(text):\n",
    "    text=re.sub('[%s]' % re.escape(string.punctuation), ' ',text)\n",
    "    text = text.replace('ÿõ', \"\")\n",
    "    text=re.sub('\\s',' ',text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def normalise_text(df):\n",
    "    try:\n",
    "        df['review']=df['review'].apply(lower_case)\n",
    "        df['review']=df['review'].apply(remove_sw)\n",
    "        df['review']=df['review'].apply(remove_num)\n",
    "        df['review']=df['review'].apply(removing_punc)\n",
    "        df['review']=df['review'].apply(removing_urls)\n",
    "        df['review']=df['review'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "371dc9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film version sandra bernhard one woman broadwa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>switched cable whim treated quite surprise alt...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plot film contains hole could drive massive tr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amusing humor fall flat decent acting quite at...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>say movie terrible good two day earlier watche...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  film version sandra bernhard one woman broadwa...  negative\n",
       "1  switched cable whim treated quite surprise alt...  positive\n",
       "2  plot film contains hole could drive massive tr...  negative\n",
       "3  amusing humor fall flat decent acting quite at...  negative\n",
       "4  say movie terrible good two day earlier watche...  negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=normalise_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b13577d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    517\n",
       "positive    483\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83d31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment']=df['sentiment'].map({'positive':1,'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdea44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b94f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as itsalok2\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as itsalok2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"itsalok2/nlp_end_to_end\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"itsalok2/nlp_end_to_end\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository itsalok2/nlp_end_to_end initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository itsalok2/nlp_end_to_end initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='itsalok2', repo_name='nlp_end_to_end', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1910a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/4790d107af0a4222930a42f52a66eed7', creation_time=1759923292487, experiment_id='0', last_update_time=1759923292487, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Logistic Regression Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd951e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-08 19:28:48,608 - INFO - starting MLFlow runs....\n",
      "2025-10-08 19:28:49,609 - INFO - logging preprocessing parameters\n",
      "2025-10-08 19:28:50,895 - INFO - initialising loginstic regression model\n",
      "2025-10-08 19:28:50,897 - INFO - fitting the model\n",
      "2025-10-08 19:28:51,035 - INFO - model training complete\n",
      "2025-10-08 19:28:51,036 - INFO - making predection\n",
      "2025-10-08 19:28:51,038 - INFO - calculating evaluation metrics\n",
      "2025-10-08 19:28:51,054 - INFO - Logging evaluation metrics...\n",
      "2025-10-08 19:28:52,364 - INFO - saving and logging the model\n",
      "\u001b[31m2025/10/08 19:28:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-10-08 19:29:00,871 - INFO - Model training and logging completed in 11.26 seconds.\n",
      "2025-10-08 19:29:00,872 - INFO - Accuracy: 0.765\n",
      "2025-10-08 19:29:00,873 - INFO - Precision: 0.7692307692307693\n",
      "2025-10-08 19:29:00,874 - INFO - Recall: 0.7291666666666666\n",
      "2025-10-08 19:29:00,875 - INFO - F1 Score: 0.7486631016042781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run crawling-grub-185 at: https://dagshub.com/itsalok2/nlp_end_to_end.mlflow/#/experiments/0/runs/19aec8b6e17241c5a920a31b5b867865\n",
      "üß™ View experiment at: https://dagshub.com/itsalok2/nlp_end_to_end.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "import os\n",
    "\n",
    "config={\n",
    "    'max_fea':400,\n",
    "    'test_size':0.2,\n",
    "    'max_iter':1000\n",
    "}\n",
    "\n",
    "vec=CountVectorizer(max_features=config['max_fea'])\n",
    "x=vec.fit_transform(df['review'])\n",
    "y=df['sentiment']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=config['test_size'],random_state=42)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logging.info('starting MLFlow runs....')\n",
    "\n",
    "with mlflow.start_run():\n",
    "    st=time.time()\n",
    "\n",
    "    try:\n",
    "        logging.info('logging preprocessing parameters')\n",
    "        mlflow.log_param('vectorizer','tfidf vectorizer')\n",
    "        mlflow.log_param('num_features',config['max_fea'])\n",
    "        mlflow.log_param('test_size',config['test_size'])\n",
    "        mlflow.log_param('max_iter',config['max_iter'])\n",
    "        \n",
    "        logging.info('initialising loginstic regression model')\n",
    "        model=LogisticRegression(max_iter=config['max_iter'])\n",
    "\n",
    "        logging.info('fitting the model')\n",
    "        model.fit(x_train,y_train)\n",
    "        logging.info('model training complete')\n",
    "\n",
    "        logging.info('making predection')\n",
    "        y_pred=model.predict(x_test)\n",
    "\n",
    "        logging.info('calculating evaluation metrics')\n",
    "        accuracy=accuracy_score(y_test,y_pred)\n",
    "        precision=precision_score(y_test,y_pred)\n",
    "        recall=recall_score(y_test,y_pred)\n",
    "        f1=f1_score(y_test,y_pred)\n",
    "\n",
    "        logging.info(\"Logging evaluation metrics...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        logging.info('saving and logging the model')\n",
    "        mlflow.sklearn.log_model(model,'model')\n",
    "\n",
    "        et=time.time()\n",
    "        logging.info(f\"Model training and logging completed in {et - st:.2f} seconds.\")\n",
    "\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/08 19:30:23 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 0.24.1 <= scikit-learn <= 1.6.1, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
      "2025-10-08 19:30:23,517 - INFO - Starting MLflow auto-logged run...\n",
      "2025-10-08 19:30:23,983 - INFO - Initializing Logistic Regression model...\n",
      "2025-10-08 19:30:23,984 - INFO - Fitting the model...\n",
      "2025/10/08 19:30:23 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025-10-08 19:30:38,739 - INFO - Model training complete.\n",
      "2025-10-08 19:30:38,740 - INFO - Making predictions...\n",
      "2025-10-08 19:30:39,104 - INFO - Calculating evaluation metrics...\n",
      "2025-10-08 19:30:43,280 - INFO - Accuracy: 0.745, Precision: 0.7368421052631579, Recall: 0.7291666666666666, F1 Score: 0.7329842931937173\n",
      "2025-10-08 19:30:43,281 - INFO - Training completed in 19.30 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run flawless-fowl-187 at: https://dagshub.com/itsalok2/nlp_end_to_end.mlflow/#/experiments/0/runs/27c88be752cd4c8e9d95cc41ebde84f4\n",
      "üß™ View experiment at: https://dagshub.com/itsalok2/nlp_end_to_end.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import logging\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Enable MLflow autolog for XGBoost\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def objective(trial):\n",
    "    # Child run for each trial\n",
    "    with mlflow.start_run(run_name=f\"Trial_{trial.number}\", nested=True):\n",
    "        logging.info(f\"Starting trial {trial.number}...\")\n",
    "\n",
    "        # Suggest hyperparameters including num_boost_round\n",
    "        param = {\n",
    "            \"verbosity\": 0,\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"error\",  # 1 - accuracy\n",
    "            \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n",
    "            \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 10.0, log=True),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 10.0, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3, log=True),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 10.0, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "        }\n",
    "        num_boost_round = trial.suggest_int(\"num_boost_round\", 50, 300)\n",
    "\n",
    "        # Convert data to DMatrix\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "        # Train with early stopping on validation accuracy\n",
    "        bst = xgb.train(\n",
    "            param,\n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(dtrain,'training'),(dvalid, \"validation\")],\n",
    "            early_stopping_rounds=10,\n",
    "            verbose_eval=True,\n",
    "            eval_metric='error'\n",
    "        )\n",
    "\n",
    "        # Predict\n",
    "        preds = bst.predict(dvalid)\n",
    "        pred_labels = [1 if p > 0.5 else 0 for p in preds]\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy = accuracy_score(y_valid, pred_labels)\n",
    "        precision = precision_score(y_valid, pred_labels)\n",
    "        recall = recall_score(y_valid, pred_labels)\n",
    "        f1 = f1_score(y_valid, pred_labels)\n",
    "\n",
    "        # Log metrics explicitly\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    return accuracy  # Optuna maximizes accuracy\n",
    "\n",
    "# Parent run\n",
    "with mlflow.start_run(run_name=\"XGBoost_Hyperparameter_Tuning_Parent\"):\n",
    "    logging.info(\"Starting Optuna hyperparameter tuning...\")\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "\n",
    "    logging.info(\"Hyperparameter tuning complete.\")\n",
    "    logging.info(f\"Best trial parameters: {study.best_trial.params}\")\n",
    "    logging.info(f\"Best accuracy: {study.best_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88923094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k8s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
