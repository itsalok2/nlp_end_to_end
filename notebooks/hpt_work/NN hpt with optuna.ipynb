{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caff73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import optuna\n",
    "import dagshub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dagshub.init(repo_owner='itsalok2', repo_name='nlp_end_to_end', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"Neural_Network_with_optuna\")\n",
    "\n",
    "# Load data\n",
    "emd_df = pd.read_csv('/home/alok_kumar/kubernetes/nlp_end_to_end/data/processed/embedded_data/embedded_dataframe.csv')\n",
    "x = emd_df.iloc[:, :-1].values\n",
    "y = emd_df.iloc[:, -1].values\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    activ = trial.suggest_categorical('activation', ['relu', 'tanh', 'selu'])\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-1, log=True)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape=(x_train.shape[1],)))\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        units = trial.suggest_int(f\"unit_{i}\", 8, 32, step=4)\n",
    "        model.add(layers.Dense(units=units, activation=activ))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True)\n",
    "    \n",
    "    # Each trial is a nested run under the parent\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params({\n",
    "            \"num_layers\": num_layers,\n",
    "            \"activation\": activ,\n",
    "            \"lr\": lr,\n",
    "            **{f\"units_{i}\": trial.params.get(f'unit_{i}') for i in range(num_layers)}\n",
    "        })\n",
    "\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            epochs=25,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            callbacks=[es],\n",
    "                            verbose=0)\n",
    "\n",
    "        y_pred = (model.predict(x_val) > 0.5).astype('int32')\n",
    "\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"val_precision\": precision,\n",
    "            \"val_recall\": recall,\n",
    "            \"val_f1\": f1,\n",
    "            \"val_accuracy\": accuracy\n",
    "        })\n",
    "\n",
    "        return max(history.history['val_accuracy'])\n",
    "\n",
    "# Start a parent MLflow run\n",
    "with mlflow.start_run(run_name=\"optuna_study_parent\"):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=25)\n",
    "\n",
    "    # Log best trial params & value in parent run\n",
    "    mlflow.log_params(study.best_trial.params)\n",
    "    mlflow.log_metric(\"best_val_accuracy\", study.best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'num_layers': 3,\n",
    " 'activation': 'relu',\n",
    " 'lr': 0.044980501630228376,\n",
    " 'unit_0': 8,\n",
    " 'unit_1': 8,\n",
    " 'unit_2': 8}\n",
    "\n",
    "emd_df = pd.read_csv('/home/alok_kumar/kubernetes/nlp_end_to_end/data/processed/embedded_data/embedded_dataframe.csv')\n",
    "x = emd_df.iloc[:, :-1].values\n",
    "y = emd_df.iloc[:, -1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(layers.Input(shape=(x_train.shape[1],)))\n",
    "\n",
    "for i in range(params['num_layers']):\n",
    "    model.add(layers.Dense(units=params[f'unit_{i}'],activation=params['activation']))\n",
    "\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=params['lr']),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "es=EarlyStopping(monitor='val_accuracy',patience=8,restore_best_weights=True)\n",
    "\n",
    "history=model.fit(x_train,y_train,\n",
    "                  validation_split=0.2,\n",
    "                  epochs=25,\n",
    "                  batch_size=32,\n",
    "                  verbose=1,\n",
    "                  callbacks=[es])\n",
    "\n",
    "y_pred=(model.predict(x_test)>0.5).astype('int32').flatten()\n",
    "\n",
    "print('accuracy',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b44fa59",
   "metadata": {},
   "source": [
    "### working with stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Import major classifiers\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron, RidgeClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# -----------------------\n",
    "# Load and prepare dataset\n",
    "# -----------------------\n",
    "emd_df = pd.read_csv('/home/alok_kumar/kubernetes/nlp_end_to_end/data/processed/embedded_data/embedded_dataframe.csv')\n",
    "x = emd_df.iloc[:, :-1].values\n",
    "y = emd_df.iloc[:, -1].values\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -----------------------\n",
    "# Define base learners\n",
    "# -----------------------\n",
    "base_learners = [\n",
    "    ('logreg', LogisticRegression(max_iter=500)),\n",
    "    ('sgd', SGDClassifier(max_iter=1000, tol=1e-3)),\n",
    "    ('perceptron', Perceptron(max_iter=500)),\n",
    "    ('ridge', RidgeClassifier()),\n",
    "    ('passive', PassiveAggressiveClassifier(max_iter=1000)),\n",
    "    ('gnb', GaussianNB()),\n",
    "    ('bnb', BernoulliNB()),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('svc', SVC(probability=True, kernel='rbf')),\n",
    "    ('linsvc', LinearSVC(max_iter=2000)),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('gb', GradientBoostingClassifier()),\n",
    "    ('ada', AdaBoostClassifier()),\n",
    "    ('et', ExtraTreesClassifier()),\n",
    "    ('bag', BaggingClassifier()),\n",
    "    ('mlp', MLPClassifier(max_iter=1000))\n",
    "]\n",
    "\n",
    "# -----------------------\n",
    "# Define meta-model (final estimator)\n",
    "# -----------------------\n",
    "final_estimator = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Create the stacking classifier\n",
    "# -----------------------\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=final_estimator,\n",
    "    cv=5,              # 5-fold cross-validation for meta-model\n",
    "    n_jobs=-1,         # use all cores\n",
    "    passthrough=False  # whether to include original features in meta-model\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Train and evaluate\n",
    "# -----------------------\n",
    "stack_clf.fit(x_train, y_train)\n",
    "y_pred = stack_clf.predict(x_val)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='weighted')\n",
    "recall = recall_score(y_val, y_pred, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275f340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k8s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
