{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328c6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dagshub\n",
    "import logging\n",
    "import os\n",
    "import optuna\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb4f606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film version sandra bernhard one woman broadwa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>switched cable whim treated quite surprise alt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plot film contains hole could drive massive tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amusing humor fall flat decent acting quite at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>say movie terrible good two day earlier watche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  film version sandra bernhard one woman broadwa...          0\n",
       "1  switched cable whim treated quite surprise alt...          1\n",
       "2  plot film contains hole could drive massive tr...          0\n",
       "3  amusing humor fall flat decent acting quite at...          0\n",
       "4  say movie terrible good two day earlier watche...          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf11469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as itsalok2\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as itsalok2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"itsalok2/nlp_end_to_end\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"itsalok2/nlp_end_to_end\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository itsalok2/nlp_end_to_end initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository itsalok2/nlp_end_to_end initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/6941837213f54b508e4a8521acf208ac', creation_time=1759994312127, experiment_id='1', last_update_time=1759994312127, lifecycle_stage='active', name='xgboost with optuna', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dagshub.init(repo_owner='itsalok2', repo_name='nlp_end_to_end', mlflow=True)\n",
    "mlflow.set_experiment('xgboost with optuna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33fb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# 2️⃣ Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3️⃣ Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=500,  # remove common stopwords\n",
    "    ngram_range=(1,2)      # consider unigrams and bigrams\n",
    ")\n",
    "\n",
    "# 4️⃣ Fit on training data and transform both\n",
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_test_tfidf  = tfidf.transform(x_test)\n",
    "\n",
    "\n",
    "# Enable MLflow autolog for XGBoost\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def objective(trial):\n",
    "    # Child run for each trial\n",
    "    with mlflow.start_run(run_name=f\"Trial_{trial.number}\", nested=True):\n",
    "        logging.info(f\"Starting trial {trial.number}...\")\n",
    "\n",
    "        # Suggest hyperparameters including num_boost_round\n",
    "        param = {\n",
    "            \"verbosity\": 0,\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"error\",  # 1 - accuracy\n",
    "            \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n",
    "            \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 10.0, log=True),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 10.0, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15),\n",
    "            \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3, log=True),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 10.0, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "        }\n",
    "        num_boost_round = trial.suggest_int(\"num_boost_round\", 300, 1500)\n",
    "\n",
    "        # Convert data to DMatrix\n",
    "        dtrain = xgb.DMatrix(x_train_tfidf, label=y_train)\n",
    "        dtest = xgb.DMatrix(x_test_tfidf, label=y_test)\n",
    "\n",
    "        # Train with early stopping on validation accuracy\n",
    "        bst = xgb.train(\n",
    "            param,\n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(dtrain,'training'),(dtest, \"validation\")],\n",
    "            early_stopping_rounds=10,\n",
    "            verbose_eval=True,\n",
    "        )\n",
    "\n",
    "        # Predict\n",
    "        preds = bst.predict(dtest)\n",
    "        pred_labels = [1 if p > 0.5 else 0 for p in preds]\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy = accuracy_score(y_test, pred_labels)\n",
    "        precision = precision_score(y_test, pred_labels)\n",
    "        recall = recall_score(y_test, pred_labels)\n",
    "        f1 = f1_score(y_test, pred_labels)\n",
    "\n",
    "        # Log metrics explicitly\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    return accuracy  # Optuna maximizes accuracy\n",
    "\n",
    "# Parent run\n",
    "with mlflow.start_run(run_name=\"XGBoost_Hyperparameter_Tuning_Parent_500fea\"):\n",
    "    logging.info(\"Starting Optuna hyperparameter tuning...\")\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "\n",
    "    logging.info(\"Hyperparameter tuning complete.\")\n",
    "    logging.info(f\"Best trial parameters: {study.best_trial.params}\")\n",
    "    logging.info(f\"Best accuracy: {study.best_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af53603",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['review']\n",
    "y=df['sentiment']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "tfidf=TfidfVectorizer(max_features=500,ngram_range=(1,2))\n",
    "x_train_tfidf=tfidf.fit_transform(x_train)\n",
    "x_test_tfidf=tfidf.transform(x_test)\n",
    "\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(run_name=f\"Trial_{trial.number}\",nested=True):\n",
    "        logging.info(f\"starting trial {trial.number}...\")\n",
    "\n",
    "        params={\n",
    "            'verbosity':1,\n",
    "            'objective':'binary:logistic',\n",
    "            'eval_metric':'error',\n",
    "            'device':'cuda',\n",
    "            'tree_method': 'hist',  \n",
    "            'booster':'dart',\n",
    "            'lambda':trial.suggest_float('lambda',1e-3,1.0,log=True),\n",
    "            'alpha':trial.suggest_float('alpha',1e-3,2.0,log=True),\n",
    "            'max_depth':trial.suggest_int('max_depth',5,15),\n",
    "            'eta':trial.suggest_float('eta',0.01, 0.3, log=True),\n",
    "            'gamma':trial.suggest_float('gamma',1e-3, 1, log=True),\n",
    "            'subsample':trial.suggest_float('subsample',0.5,1.0),\n",
    "            'colsample_bytree':trial.suggest_float('colsample_bytree',0.5,0.8)\n",
    "        }\n",
    "\n",
    "        num_boost_round=trial.suggest_int('num_boost_round',300,1400)\n",
    "\n",
    "        dtrain=xgb.DMatrix(x_train_tfidf,label=y_train)\n",
    "        dtest=xgb.DMatrix(x_test_tfidf,label=y_test)\n",
    "\n",
    "        bst=xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(dtrain,'training'),(dtest,'testing')],\n",
    "            early_stopping_rounds=10,\n",
    "            verbose_eval=50\n",
    "        )\n",
    "\n",
    "        preds=bst.predict(dtest)\n",
    "        pred_labels=[1 if p>0.5 else 0 for p in preds]\n",
    "\n",
    "        accuracy=accuracy_score(y_test,pred_labels)\n",
    "        precision = precision_score(y_test, pred_labels)\n",
    "        recall = recall_score(y_test, pred_labels)\n",
    "        f1 = f1_score(y_test, pred_labels)\n",
    "\n",
    "        # Log metrics explicitly\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy':accuracy,\n",
    "            'precision':precision,\n",
    "            'f1_score':f1,\n",
    "            'recall':recall\n",
    "        })\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost_Hyperparameter_Tuning_Parent_500fea\"):\n",
    "    logging.info('starting optuna hyperparameter tuning...')\n",
    "    study=optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective,n_trials=30)\n",
    "\n",
    "    logging.info(\"Hyperparameter tuning complete.\")\n",
    "    logging.info(f\"Best trial parameters: {study.best_trial.params}\")\n",
    "    logging.info(f\"Best accuracy: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b40d22",
   "metadata": {},
   "source": [
    "# using the word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_preprocess function:\n",
    "                                        # Lowercases text – all letters become lowercase.\n",
    "                                        # Removes punctuation and special characters – keeps only alphabetic tokens.\n",
    "                                        # Tokenizes the text – splits the text into a list of words.\n",
    "                                        # Optional length filtering – you can keep words only between a min_len and max_len.\n",
    "import gensim\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "model=KeyedVectors.load_word2vec_format('/home/alok_kumar/kubernetes/nlp_end_to_end/notebooks/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin',binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb(text,model):\n",
    "    tokens=simple_preprocess(text)\n",
    "    valid_tokens=[token for token in tokens if token in model.key_to_index]\n",
    "    if not valid_tokens:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    embeddings=np.mean([model[token] for token in valid_tokens],axis=0)\n",
    "    return embeddings\n",
    "\n",
    "x_embeddings=np.array([get_emb(text=text,model=model) for text in df['review']])\n",
    "y=df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ab9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_df=pd.DataFrame(x_embeddings,columns=[f\"fea_{i}\" for i in range(300)])\n",
    "emd_df['sentiment']=y\n",
    "\n",
    "x=emd_df.iloc[:,:-1]\n",
    "y=emd_df.iloc[:,-1]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "mlflow.set_experiment('xgboost with word2vec(not with error)')\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\",nested=True):\n",
    "        logging.info(f\"starting trial {trial.number}...\")\n",
    "\n",
    "        params={\n",
    "            'verbosity':1,\n",
    "            'objective':'binary:logistic',\n",
    "            'eval_metric':'error',\n",
    "            'device':'cuda',\n",
    "            'tree_method':'hist',\n",
    "            'booster':'dart',\n",
    "            'lambda':trial.suggest_float('lambda',1e-3,1.0,log=True),\n",
    "            'alpha':trial.suggest_float('alpha',1e-3,2.0,log=True),\n",
    "            'max_depth':trial.suggest_int('max_depth',5,15),\n",
    "            'eta':trial.suggest_float('eta',0.01,0.3,log=True),\n",
    "            'gamma':trial.suggest_float('gamma',1e-3, 1, log=True),\n",
    "            'subsample':trial.suggest_float('subsample',0.5,1.0),\n",
    "            'colsample_bytree':trial.suggest_float('colsample_bytree',0.5,0.8)\n",
    "        }\n",
    "\n",
    "        num_boost_round=trial.suggest_int('num_boos_round',300,1400)\n",
    "\n",
    "        dtrain=xgb.DMatrix(x_train,label=y_train)\n",
    "        dtest=xgb.DMatrix(x_test,label=y_test)\n",
    "\n",
    "        bst=xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(dtrain,'training'),(dtest,'testing')],\n",
    "            early_stopping_rounds=10,\n",
    "            verbose_eval=25\n",
    "        )\n",
    "\n",
    "        preds=bst.predict(dtest)\n",
    "        pred_labels=[1 if p>0.5 else 0 for p in preds]\n",
    "\n",
    "        accuracy=accuracy_score(y_test,pred_labels)\n",
    "        precision = precision_score(y_test, pred_labels)\n",
    "        recall = recall_score(y_test, pred_labels)\n",
    "        f1 = f1_score(y_test, pred_labels)\n",
    "\n",
    "        # Log metrics explicitly\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy':accuracy,\n",
    "            'precision':precision,\n",
    "            'recall':recall,\n",
    "            'f1_score':f1\n",
    "        })\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost_Hyperparameter_Tuning_Parent_word2vec\"):\n",
    "    logging.info('starting optuna hyperparameter tuning...')\n",
    "    study=optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective,n_trials=25)\n",
    "\n",
    "    logging.info(\"Hyperparameter tuning complete.\")\n",
    "    logging.info(f\"Best trial parameters: {study.best_trial.params}\")\n",
    "    logging.info(f\"Best accuracy: {study.best_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c505389",
   "metadata": {},
   "source": [
    "### Using the Keras tuner with the above word2vec embedding to test out the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e178b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "model=KeyedVectors.load_word2vec_format('word2vec.vec',binary=True)\n",
    "\n",
    "def get_emb(text,model):\n",
    "    tokens=simple_preprocess(text)\n",
    "    valid_tokens=[token for token in tokens if token in model.key_to_index]\n",
    "    if not valid_tokens:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    embeddings=np.mean([model[token] for token in valid_tokens],axis=0)\n",
    "    return embeddings\n",
    "\n",
    "x_embeddings=np.array([get_emb(text=text,model=model) for text in df['review']])\n",
    "y=df['sentiment'].values\n",
    "\n",
    "emd_df=pd.DataFrame(x_embeddings,columns=[f\"fea_{i}\" for i in range(300)])\n",
    "emd_df['sentiment']=y\n",
    "\n",
    "x=emd_df.iloc[:,:-1]\n",
    "y=emd_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41462b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_df.to_csv('/home/alok_kumar/kubernetes/nlp_end_to_end/data/processed/embedded_data/embedded_dataframe.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83716c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                    # next time use this\n",
    "emd_df=pd.read_csv('/home/alok_kumar/kubernetes/nlp_end_to_end/data/processed/embedded_data/embedded_dataframe.csv')\n",
    "x=emd_df.iloc[:,:-1]\n",
    "y=emd_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a25fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a099cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k8s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
